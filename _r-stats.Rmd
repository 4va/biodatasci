---
title: 'Essential Statistics with R'
---

This workshop will provide hands-on instruction and exercises covering basic statistical analysis in R. This will cover descriptive statistics, _t_-tests, linear models, chi-square, clustering, dimensionality reduction, and resampling strategies. We will also cover methods for "tidying" model results for downstream visualization and summarization. 

**Prerequisites: [Familiarity with R](r-basics.html) is _required_** (including working with [data frames](r-dataframes.html), installing/using packages, importing data, and saving results); familiarity with [dplyr](r-dplyr-yeast.html) and [ggplot2](r-viz-gapminder.html) packages is highly recommended. 

**You must [complete the basic R setup here](setup.html#R) _prior to class_.** This includes installing R, RStudio, and the required packages. Please [contact one of the instructors](people.html) _prior to class_ if you are having difficulty with any of the setup. Please bring your laptop and charger cable to class.


```{r, echo=FALSE, message=FALSE, eval=TRUE}
library(knitr)
opts_chunk$set(message=FALSE, warning=FALSE, eval=TRUE, echo=TRUE, cache=FALSE)
options(digits=3)
options(max.print=200)
.ex <- 1 # Track ex numbers w/ hidden var. Increment each ex: `r .ex``r .ex=.ex+1`
```


```{r make_data, include=FALSE, eval=FALSE}
###############################################################################
############# THIS CHUNK IS ONLY HERE TO SHOW HOW I MADE THE DATA #############
###############################################################################
library(dplyr)

# nhdemo <- Hmisc::sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT") %>% tbl_df 
# nhbody <- Hmisc::sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/BMX_G.XPT") %>% tbl_df
nhhiq <-  Hmisc::sasxport.get("http://wwwn.cdc.gov/nchs/nhanes/2011-2012/HIQ_G.XPT") %>% 
  transmute(ID=as.integer(seqn), Insured=as.integer(hiq011)) %>% 
  mutate(Insured=recode(Insured, `1`="Yes", `2`="No", .default=NA_character_, .missing=NA_character_))

nh <- NHANES::NHANES %>% filter(SurveyYr=="2011_12") %>% select(-SurveyYr) %>% inner_join(nhhiq, by="ID")

nh <- transmute(nh, 
                id=ID,
                Gender, 
                Age,
                Race=Race3, 
                Education, 
                MaritalStatus, 
                RelationshipStatus=if_else(MaritalStatus=="Married"|MaritalStatus=="LivePartner", "Committed", "Single", NA_character_),
                Insured,
                Income=HHIncomeMid,
                Poverty, 
                HomeRooms, 
                HomeOwn, 
                Work, 
                Weight, 
                Height, 
                BMI,
                Pulse,
                BPSys=BPSysAve, 
                BPDia=BPDiaAve, 
                Testosterone, 
                HDLChol=DirectChol, 
                TotChol,
                Diabetes,
                DiabetesAge,
                nPregnancies,
                nBabies,
                SleepHrsNight,
                PhysActive,
                PhysActiveDays,
                AlcoholDay,
                AlcoholYear,
                SmokingStatus = mosaic::derivedFactor(
                  Current = SmokeNow == "Yes",
                  Former = SmokeNow == "No",
                  Never  = Smoke100 == "No"
                ))

nh %>% readr::write_csv("data/nhanes.csv")
nh <- readr::read_csv("data/nhanes.csv")
nh <- nh %>% mutate_if(is.factor, funs(as.character))
nhad <- nh %>% filter(Age >=18, BMI>1)

```


## Our data: NHANES

The data we're going to work with comes from the National Health and Nutrition Examination Survey (NHANES) program at the CDC. You can read a lot more about NHANES on the [CDC's website](http://www.cdc.gov/nchs/nhanes/) or [Wikipedia](https://en.wikipedia.org/wiki/National_Health_and_Nutrition_Examination_Survey). NHANES is a research program designed to assess the health and nutritional status of adults and children in the United States. The survey is one of the only to combine both survey questions and physical examinations. It began in the 1960s and since 1999 examines a nationally representative sample of about 5,000 people each year. The NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The physical exam includes medical, dental, and physiological measurements, as well as several standard laboratory tests. NHANES is used to determine the prevalence of major diseases and risk factors for those diseases. NHANES data are also the basis for national standards for measurements like height, weight, and blood pressure. Data from this survey is used in epidemiology studies and health sciences research, which help develop public health policy, direct and design health programs and services, and expand the health knowledge for the Nation.

We are using a small slice of this data. We're only using a handful of variables from the 2011-2012 survey years on about 5,000 individuals. The CDC uses a [sampling strategy](http://www.cdc.gov/nchs/data/series/sr_02/sr02_162.pdf) to purposefully oversample certain subpopulations like racial minorities. Naive analysis of the original NHANES data can lead to mistaken conclusions because the percentages of people from each racial group in the data are different from general population. The 5,000 individuals here are resampled from the larger NHANES study population to undo these oversampling effects, so you can treat this as if it were a simple random sample from the American population.

You can download the data at [the link above](data.html). The file is called [**nhanes.csv**](data/nhanes.csv). There's also a [data dictionary (filename **nhanes_dd.csv**)](data/nhanes_dd.csv) that lists and describes each variable in our NHANES dataset. This table is copied below.

```{r, echo=FALSE}
# library(dplyr)
# read.csv("data/nhanes_dd.csv", header=TRUE) %>% 
#   mutate(Variable=paste0("<strong>", Variable, "</strong>")) %>% 
#   # DT::datatable(rownames=FALSE, caption="NHANES Data Dictionary", escape=FALSE)
#   kable()
# haven't loaded libraries yet, keep it this way.
kable(transform(read.csv("data/nhanes_dd.csv", header=TRUE), Variable=paste0("<strong>", Variable, "</strong>")))
```


## Descriptive stats & EDA

- Mean, median
- summary
- missing data, anyNA
- range
- na.rm
- xtabs eg. `xtabs(~Gender+Diabetes, data=nh)`, addmargins

<!--

----

_Everything past this point is scratch_

----


## Scratch

- Jo Hardin's useR talk:

    - [useR talk on dynamic data in the classroom](https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Dynamic-Data-in-the-Statistics-Classroom)
    - [repo on GitHub](https://github.com/hardin47/dynamicdata)
    - [slides](https://rawgit.com/hardin47/DynamicData/master/DynDatauseR.html)
- [Info on Framingham data](https://grimshaw-wiki.byu.edu/index.php/Risk_Factors_for_Cardiovascular_Disease_from_Framingham_Data)


```{r}
# Turn off evaluation of all further R chunks.
opts_chunk$set(eval=FALSE)
```


```{r}
library(dplyr)
library(ggplot2)

nhad <- nh %>% filter(Age >=18, BMI>1)
  
boxplot(BMI ~ RelationshipStatus, data=nhad, xlab="Relationship Status", ylab="BMI")

ggplot(nhad, aes(RelationshipStatus, BMI))+ geom_violin(color="orange")+ 
  xlab("Relationship Status") + ylab("BMI")

t.test(BMI ~ RelationshipStatus, data=nhad)
wilcox.test(BMI ~ RelationshipStatus, data=nhad)
anova(lm(BMI ~ RelationshipStatus, data=nhad))
summary(lm(BMI ~ RelationshipStatus, data=nhad))


ggplot(nhad, aes(x=Height, y=Weight, color=Gender)) + geom_point(alpha=.5)+ 
  xlab("Height") + ylab("Weight") + ggtitle("Height vs Weight by Gender")

last_plot() + geom_smooth(alpha=.1)
  
ggplot(nhad, aes(x=bmxht, y=bmxwt, group=gender, color=gender)) + 
  xlab("Height") + ylab("Weight") + geom_point(alpha=.5)+ 
  stat_smooth(alpha=1)+ 
  ggtitle("Height vs Weight by Gender with Smooth Regression Fit")

```



## t-tests

- `boxplot`
- `t.test`
- `power.t.test`
- welch correction
- wilcoxon test

## anova & linear models

- lm
- anova(fit)
- plot(fit)
- predict(fit, df)
- coefficients(fit)
- tidy(fit)


## Chi-square

- `xtabs %>% chisq.test`

```{r}
xtabs(~Race+Insured, data=nhad)
tab <- with(nhad, table(Race, Insured))
tab
addmargins(tab)
prop.table(tab)
prop.table(tab, margin=1)
chisq.test(tab)

with(nhad, table(Race, Insured)) %>% prop.table(margin=1)
```


## logistic regression

- `glm(..., family='binomial')`

```{r}
glm(factor(Insured)~Race, data=nhad, family='binomial') %>% tidy
glm(factor(Insured)~0+Race, data=nhad, family='binomial') %>% tidy
fit <- glm(factor(Insured)~Age+Race+Age*Race, data=nhad, family='binomial') 
summary(fit)
tidy(fit)
with(fit, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
logLik(fit)
# http://www.r-bloggers.com/evaluating-logistic-regression-models/
fit2 <- glm(factor(Insured)~Race, data=nhad, family='binomial') 
with(fit2, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
anova(fit, fit2, test="Chisq")
library(lmtest)
lrtest(fit, fit2)
library(caret)
varImp(fit)
```

## Advanced

### Resampling

### Machine learning, classification, etc.


## From Hardin's Talk

https://github.com/hardin47/dynamicdata

## Introduction

The NHANES data come from the National Health and Nutrition Examination Survey, surveys given nationwide by the Center for Disease Controls (CDC). The data are collected to assess the health and well being of adults and children throughout the United States.  The survey is one of the only to combine both survey questions and physical examinations.

## Data information & loading data

We download data on demographic information and body image.  The data are in SAS format, but R has no trouble scraping the data from the NHANES website and uploading it into R.

```{r, include=FALSE, eval=FALSE}
library(Hmisc)
library(dplyr)
library(ggplot2)

nhdemo <- sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT")
nhdemo <- mutate(nhdemo, gender = ifelse(nhdemo$riagendr==1, "male", "female")) 

nhbody <- sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/BMX_G.XPT")

nhbody <- sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/BMX_G.XPT")

nhhiq <-  sasxport.get("http://wwwn.cdc.gov/nchs/nhanes/2011-2012/HIQ_G.XPT") %>% 
  transmute(seqn=as.integer(seqn), hiq011=as.integer(hiq011)) %>% as_data_frame

comb <- inner_join(nhbody, nhdemo, by = "seqn")
```


Additionally, the NHANES data were collected using a cluster sampling scheme, so it is important to use the variables which describe the weights on the sampling to create a sample which is reflective of the population.  See the following for more information: http://web.grinnell.edu/individuals/kuipers/stat2labs/weights.html, ?NHANES (within R, using the NHANES packages), http://www.cdc.gov/nchs/data/series/sr_02/sr02_162.pdf.


```{r}
numobs = 2000
SRSsample <- sample(1:nrow(comb), numobs, replace=FALSE,
       prob=comb$wtmec2yr/sum(comb$wtmec2yr))
comb <- comb[SRSsample,]
```


## Using dynamic data within a typical classroom


One research question of interest is whether people in a committed relationship have a higher BMI than those who are not.  Note that a causal connection cannot be made here, but we are justified in thinking about the data as a good random sample from the US population.  We filter only the adults out of the sample and also created a relationship variable as to whether or not the individual is in a committed relationship.

The boxplots and violin plots both demonstrate that there is not a substantial difference between the BMI for those in committed relationships versus those who are not.  The tests of significance validate the ideas from the descriptive statistics.

It is worth noting here that the sample size is quite large.  If students repeat this analysis with different variables, it should be noted that very small effect sizes can be seen with large datasets.  A small p-value might indicate that there are significant effects, but an extra interpretation as to whether the effect is a practical difference warrants consideration.  It does not seem that the small *average* effect on BMI of being in a relationship is of any particular note when considering the large standard deviation across individual BMIs of both groups.

Additionally, again we point out that although these data are likely a good representation of the population, they cannot be used to find causal relationships.  Indeed, even if BMI had been different on average across the two groups, we do not know if lower BMI causes one to be more likely in a committed relationship or whether a committed relationship leads to a lower BMI.  Asking your students how one could gather such information would be a productive class discussion (e.g., paired observations, measurements over time, etc.).

```{r}
adults = comb %>% 
  filter(ridageyr >=18, bmxbmi>1) %>% 
  filter(dmdmartl>0 & dmdmartl < 10) %>% 
  mutate(rel=ifelse(dmdmartl==6|dmdmartl==1, "committed", "not")) %>%
  mutate(bmi=bmxbmi)
  
boxplot(bmi ~ rel, data=adults, xlab="Relationship Status", ylab="BMI")

ggplot(adults, aes(rel, bmi))+ geom_violin(color="orange")+ 
  xlab("Relationship Status") + ylab("BMI")

t.test(bmi ~ rel, data=adults)
dim(adults)
```


## Thinking outside the box

The data we have downloaded has many variables, some of which have meanings that are not immediately obvious.  The variable names are listed at the NHANES website, for example, the demographic data is at [http://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Demographics&CycleBeginYear=2011](http://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Demographics&CycleBeginYear=2011).

```{r}
names(adults)
```

For this analysis, however, we use height and weight.  We start with a simple scatterplot of height and weight with expected results (there is a correlation between height and weight, and men tend to be taller on average than women).  When adding a smoothed curve to the data, however, we are able to discuss how smooth curves are created, how to find the SE of the smooth curve, why there is extra variability due to extremes and also due to fewer data points on the ends, extrapolation (note that the two curves have different ranges), and the outcome that slopes of the two curves are not substantially different (no interaction) though might warrant further study.


```{r}
ggplot(adults, aes(x=bmxht, y=bmxwt, group=gender, color=gender)) + geom_point(alpha=.5)+ 
  xlab("Height") + ylab("Weight") + ggtitle("Height vs Weight by Gender")
  
ggplot(adults, aes(x=bmxht, y=bmxwt, group=gender, color=gender)) + 
  xlab("Height") + ylab("Weight") + geom_point(alpha=.5)+ 
  stat_smooth(alpha=1)+ 
  ggtitle("Height vs Weight by Gender with Smooth Regression Fit")
```


## Additional ideas for analysis:

With many continuous and categorical variables, the data can be used for both standard statistical regression (e.g., linear, logistic, etc.) or machine learning predictive modeling (e.g., LASSO, support vector machines, regression trees).


-->